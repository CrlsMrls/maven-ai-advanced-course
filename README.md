# Enterprise RAG and Multi-Agent Applications

This repository contains some exercises done at the course **Enterprise RAG and Multi-Agent Applications**, offered by Hamza Farooq at Maven. For more information, please visit the [course page](https://maven.com/boring-bot/advanced-llm/).

## Week 1 - Enterprise RAG Solutions with Semantic Caching

### Exercises
- [Exercise 1a - Semantic cache using Embeddings and FAISS vector DB](./Advanced_LLMs_1a_Semantic_cache_from_scratch.ipynb)
- [Exercise 1b - RAG application using BigQuery and Redis](Advanced_LLMs_1b_BigQuery_Palm_Redis.ipynb)

### Links

- [FAISS](https://faiss.ai/) - A library for efficient similarity search and clustering of dense vectors.
- [Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard) - A leaderboard for text embedding models.
- [Redis VL](https://redis.io/docs/latest/integrate/redisvl/overview/) - Redis module for vector similarity search.
- [RAG example application](https://github.com/ranjancse26/enterprise_rag_multi_agent/blob/main/Scemantic_Caching_with_Couchbase%2C_JINA_embedding.ipynb) - Jupiter notebook with semantic caching using Couchbase and JINA embedding.


## Week 2 - Optimizing and Deploying Large Language Models

### Exercises

- [Exercise 2a - Run locally Mistral-7B-Instruct](./Advanced_LLM_Module_2a_Mistral_7b_instruct.ipynb)
- [Exercise 2b - Run previously application with GROK](Advanced_LLM_Module_2b_Testing_Mistral_7b_instruct.ipynb)
- [Exercise 2c - Fine-tuning with unsloth an Urdu chatbot](./Advanced_LLM_Module_2c_Urdu_Llama.ipynb)

### Links
- [Multi-task Language Understanding](https://paperswithcode.com/task/multi-task-language-understanding) - A collection of papers, code and evaluation results for multi-task language understanding.
- [LLM Qunatization and Inferencing Tool](https://github.com/alok-abhishek/Quantizing-LLMs-and-inferencing-Quantized-model-from-HF/) - A repository for quantizing large language models and inferencing quantized models from Hugging Face.
- [Decoding Perplexity](https://blog.uptrain.ai/decoding-perplexity-and-its-significance-in-llms/) - A blog post on decoding perplexity and its significance in large language models.
- [LM Studio](https://lmstudio.ai/) - An application for downloading and running local LLMs.
- [Are you GPU poor?](https://rahulschand.github.io/gpu_poor/) - Calculate GPU memory requirement and token/s for any LLM.
- [Language Model Evaluation Harness](https://github.com/EleutherAI/lm-evaluation-harness) - A framework for few-shot evaluation of language models.
- [Run Pod](https://www.runpod.io/) - A Globally distributed market GPU cloud.
- [Vast.ai](https://vast.ai/) - Low-cost cloud GPU rental.